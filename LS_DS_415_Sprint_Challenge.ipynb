{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S1-NLP (Python3)",
      "language": "python",
      "name": "u4-s1-nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "LS_DS_415_Sprint_Challenge.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pingao2019/DS-Unit-4-Sprint-1-NLP/blob/master/LS_DS_415_Sprint_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN500ONdGUcr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Sprint Challenge\n",
        "## *Data Science Unit 4 Sprint 1*\n",
        "\n",
        "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset/challenge). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
        "\n",
        "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more managable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
        "\n",
        "## Challenge Objectives\n",
        "*Successfully complete these all these objectives to earn a 2. There are more details on each objective further down in the notebook.*\n",
        "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
        "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
        "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
        "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnTKtcFjGUcv",
        "colab_type": "code",
        "colab": {},
        "outputId": "0578d0ad-d945-4d8d-9a91-0e9f3ba6f80c"
      },
      "source": [
        "#get dataset for analying.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "yelp = pd.read_json('./data/review_sample.json', lines=True)\n",
        "yelp.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>date</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-03-31 16:50:30</td>\n",
              "      <td>0</td>\n",
              "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
              "      <td>1</td>\n",
              "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
              "      <td>10</td>\n",
              "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-12-16 05:31:03</td>\n",
              "      <td>0</td>\n",
              "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
              "      <td>4</td>\n",
              "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
              "      <td>0</td>\n",
              "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-06-20 19:14:48</td>\n",
              "      <td>1</td>\n",
              "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
              "      <td>3</td>\n",
              "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
              "      <td>2</td>\n",
              "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
              "      <td>3</td>\n",
              "      <td>2010-07-13 00:33:45</td>\n",
              "      <td>4</td>\n",
              "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
              "      <td>1</td>\n",
              "      <td>We went here on a night where they closed off ...</td>\n",
              "      <td>5</td>\n",
              "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-06-30 02:30:01</td>\n",
              "      <td>0</td>\n",
              "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
              "      <td>4</td>\n",
              "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
              "      <td>5</td>\n",
              "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id  cool                date  funny  \\\n",
              "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
              "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
              "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
              "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
              "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
              "\n",
              "                review_id  stars  \\\n",
              "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
              "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
              "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
              "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
              "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
              "\n",
              "                                                text  useful  \\\n",
              "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
              "1  Came here for lunch Togo. Service was quick. S...       0   \n",
              "2  I've been to Vegas dozens of times and had nev...       2   \n",
              "3  We went here on a night where they closed off ...       5   \n",
              "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
              "\n",
              "                  user_id  \n",
              "0  n1LM36qNg4rqGXIcvVXv8w  \n",
              "1  5CgjjDAic2-FAvCtiHpytA  \n",
              "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
              "3  cZZnBqh4gAEy4CdNvJailQ  \n",
              "4  n9QO4ClYAS7h9fpQwa5bhA  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrRUe8aCGUdM",
        "colab_type": "code",
        "colab": {},
        "outputId": "1f16d708-01df-4477-8b90-c843c06393f6"
      },
      "source": [
        "yelp['text']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...\n",
              "1       Came here for lunch Togo. Service was quick. S...\n",
              "2       I've been to Vegas dozens of times and had nev...\n",
              "3       We went here on a night where they closed off ...\n",
              "4       3.5 to 4 stars\\n\\nNot bad for the price, $12.9...\n",
              "                              ...                        \n",
              "9995    My family and I were hungry and this Subway is...\n",
              "9996    My wife and I came here with a a couple of fri...\n",
              "9997    The food was just OK and not anything to brag ...\n",
              "9998    Today's visit is great!! Love and enjoy Town S...\n",
              "9999    This is the absolute worst place I have ever s...\n",
              "Name: text, Length: 10000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dtf225YGUdn",
        "colab_type": "text"
      },
      "source": [
        "## Part 1: Tokenize Function\n",
        "<a id=\"#p1\"></a>\n",
        "\n",
        "Complete the function `tokenize`. Your function should\n",
        "- accept one document at a time\n",
        "- return a list of tokens\n",
        "\n",
        "You are free to use any method you have learned this week.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LDL1tZFGUds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  use SpaCy for tokenizing. \n",
        "\n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "tokenizer = nlp.Defaults.create_tokenizer(nlp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIAizuU9GUd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = Tokenizer(nlp.vocab)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gaNkXEIGUeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STOP_WORDS = nlp.Defaults.stop_words.union(['\\n\\n', '\\n', ' ',  'just',  'got', 'done', 'today', 'did', 'didn',  'came', 'definitely' ,'got', 'just','really','going', 'said' ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMSd2Mj4GUej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(doc):\n",
        "    tokens_new = []\n",
        "    tokens = tokenizer(doc)\n",
        "    for token in tokens:\n",
        "        if (token.is_punct == False) and (token.text.lower() not in STOP_WORDS):\n",
        "            tokens_new.append(token.text.lower())\n",
        "    return tokens_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut36STcdGUfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_tokens = yelp['text'].apply(tokenize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRLgFpwJGUfc",
        "colab_type": "code",
        "colab": {},
        "outputId": "c24542cb-71e0-473f-a889-95037b54be8d"
      },
      "source": [
        "yelp['text_tokens'] = text_tokens\n",
        "\n",
        "yelp['text_tokens'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [beware!!!, fake,, fake,, fake....we, small, b...\n",
              "1    [lunch, togo., service, quick., staff, friendl...\n",
              "2    [i've, vegas, dozens, times, stepped, foot, ci...\n",
              "3    [went, night, closed, street, party..., best, ...\n",
              "4    [3.5, 4, stars, bad, price,, $12.99, lunch,, s...\n",
              "Name: text_tokens, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoCfJkGxGUfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import squarify\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uPlGmTbGUf-",
        "colab_type": "code",
        "colab": {},
        "outputId": "9c6c0d73-ea13-4b09-ff07-d9b36ccdd9dd"
      },
      "source": [
        "# Analyzing Tokens, Object from Base Python\n",
        "from collections import Counter\n",
        "\n",
        "# The object `Counter` takes an iterable, but you can instaniate an empty one and update it. \n",
        "word_counts = Counter()\n",
        "\n",
        "# Update it based on a split of each of our documents\n",
        "yelp['text_tokens'].apply(lambda x: word_counts.update(x))\n",
        "\n",
        "# Print out the 10 most common words\n",
        "word_counts.most_common(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('place', 3782),\n",
              " ('food', 3687),\n",
              " ('great', 3407),\n",
              " ('like', 3361),\n",
              " ('good', 3235),\n",
              " (\"it's\", 2696),\n",
              " ('service', 2573),\n",
              " ('time', 2497),\n",
              " (\"don't\", 1854),\n",
              " ('love', 1597),\n",
              " ('best', 1548),\n",
              " (\"i'm\", 1531),\n",
              " (\"didn't\", 1530),\n",
              " (\"i've\", 1513),\n",
              " ('went', 1445),\n",
              " ('ordered', 1438),\n",
              " ('come', 1428),\n",
              " ('little', 1395),\n",
              " ('nice', 1341),\n",
              " ('staff', 1272),\n",
              " ('order', 1231),\n",
              " ('try', 1225),\n",
              " ('it.', 1211),\n",
              " ('chicken', 1162),\n",
              " ('people', 1160),\n",
              " ('new', 1086),\n",
              " ('know', 1065),\n",
              " ('pretty', 1051),\n",
              " ('recommend', 1038),\n",
              " ('restaurant', 1018)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kapIxBl0GUgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXTEZDlWGUgZ",
        "colab_type": "text"
      },
      "source": [
        "## Part 2: Vector Representation\n",
        "<a id=\"#p2\"></a>\n",
        "1. Create a vector representation of the reviews\n",
        "2. Write a fake review and query for the 10 most similiar reviews, print the text of the reviews. Do you notice any patterns?\n",
        "    - Given the size of the dataset, it will probably be best to use a `NearestNeighbors` model for this. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lztO0PQcGUgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGjOtrmKGUgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using CountVectorizer to see how many words in each document.\n",
        "\n",
        "vect = CountVectorizer(stop_words='english')\n",
        "\n",
        "vect.fit(yelp['text'])\n",
        "\n",
        "dtm = vect.transform(yelp['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mISfMdskGUg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VchZeeUGUhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "wc_top20 = pd.DataFrame(dtm.sum().sort_values(ascending=False).head(20),\n",
        "                       columns=['count'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojNfdTbGGUhc",
        "colab_type": "code",
        "colab": {},
        "outputId": "489ad27a-2b41-43ab-b851-e518b4a6084f"
      },
      "source": [
        "wc_top20"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>food</th>\n",
              "      <td>5070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>place</th>\n",
              "      <td>4832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>good</th>\n",
              "      <td>4806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>great</th>\n",
              "      <td>4297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>service</th>\n",
              "      <td>3695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>like</th>\n",
              "      <td>3558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>just</th>\n",
              "      <td>3553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <td>3449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>really</th>\n",
              "      <td>2692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>got</th>\n",
              "      <td>2070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>don</th>\n",
              "      <td>1925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ve</th>\n",
              "      <td>1924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nice</th>\n",
              "      <td>1748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>best</th>\n",
              "      <td>1746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>did</th>\n",
              "      <td>1737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>love</th>\n",
              "      <td>1685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>staff</th>\n",
              "      <td>1597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order</th>\n",
              "      <td>1575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>didn</th>\n",
              "      <td>1564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>came</th>\n",
              "      <td>1553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         count\n",
              "food      5070\n",
              "place     4832\n",
              "good      4806\n",
              "great     4297\n",
              "service   3695\n",
              "like      3558\n",
              "just      3553\n",
              "time      3449\n",
              "really    2692\n",
              "got       2070\n",
              "don       1925\n",
              "ve        1924\n",
              "nice      1748\n",
              "best      1746\n",
              "did       1737\n",
              "love      1685\n",
              "staff     1597\n",
              "order     1575\n",
              "didn      1564\n",
              "came      1553"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjd7uSO-GUhs",
        "colab_type": "text"
      },
      "source": [
        "### Use TF-IDF to vectorize. TF-IDF means Term Frequency - Inverse Document Frequency. Term Frequency: Percentage of words in document for each word.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6tgyQIpGUht",
        "colab_type": "code",
        "colab": {},
        "outputId": "560e4f16-4a04-4389-fd94-7497f9ff2a51"
      },
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "# Create a vocabulary and get word counts per document.Similiar to fit_predict. Giving Percentage of words in document for each wor\n",
        "\n",
        "dtm = tfidf.fit_transform(yelp['text'])\n",
        "# Get feature names to use as dataframe column headers\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
        "tfidf\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=5000,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXBsKY4_GUh4",
        "colab_type": "code",
        "colab": {},
        "outputId": "23dd4c8e-24ca-4942-f5db-0f48046e78d8"
      },
      "source": [
        "dtm.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaGXzMMmGUiC",
        "colab_type": "code",
        "colab": {},
        "outputId": "3eb0b41b-0211-4aed-e3b5-9e0d7744983d"
      },
      "source": [
        "#### View Feature Matrix as DataFrame\n",
        "dtm.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>00pm</th>\n",
              "      <th>07</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>101</th>\n",
              "      <th>10pm</th>\n",
              "      <th>11</th>\n",
              "      <th>...</th>\n",
              "      <th>yuck</th>\n",
              "      <th>yuk</th>\n",
              "      <th>yum</th>\n",
              "      <th>yummy</th>\n",
              "      <th>yup</th>\n",
              "      <th>zero</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zucchini</th>\n",
              "      <th>était</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    00  000  00pm   07   10  100  1000  101  10pm   11  ...  yuck  yuk  yum  \\\n",
              "0  0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0  ...   0.0  0.0  0.0   \n",
              "1  0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0  ...   0.0  0.0  0.0   \n",
              "2  0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0  ...   0.0  0.0  0.0   \n",
              "3  0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0  ...   0.0  0.0  0.0   \n",
              "4  0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0  ...   0.0  0.0  0.0   \n",
              "\n",
              "   yummy  yup  zero  zone  zoo  zucchini  était  \n",
              "0    0.0  0.0   0.0   0.0  0.0       0.0    0.0  \n",
              "1    0.0  0.0   0.0   0.0  0.0       0.0    0.0  \n",
              "2    0.0  0.0   0.0   0.0  0.0       0.0    0.0  \n",
              "3    0.0  0.0   0.0   0.0  0.0       0.0    0.0  \n",
              "4    0.0  0.0   0.0   0.0  0.0       0.0    0.0  \n",
              "\n",
              "[5 rows x 5000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7cMNYn5GUiL",
        "colab_type": "code",
        "colab": {},
        "outputId": "e60e0ad5-c496-434d-c46a-c21e67b202b8"
      },
      "source": [
        "# Fit a NearestNeighbors model(K-NN)\n",
        "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "nn.fit(dtm)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m5pjxhYGUiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review = ['Wonderful burrito, great coffee, nice owner, convenient parking.']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1_WRQ0RGUij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new = tfidf.transform(review)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR43tB34GUi3",
        "colab_type": "code",
        "colab": {},
        "outputId": "45e87715-4a1a-475a-9fa9-1c54bf599368"
      },
      "source": [
        "new.todense()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQqjTdUjGUjB",
        "colab_type": "code",
        "colab": {},
        "outputId": "7620d0fe-c21b-4996-c142-604ca0e8b476"
      },
      "source": [
        "matches = nn.kneighbors(new.todense(), n_neighbors=10)[1]\n",
        "for match in matches:\n",
        "    print(yelp['text'][match])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6311    天氣很熱吃不下東西，今天我點了一個韓國冷面湯、餐後點了甜點，冰沙系列不會太甜膩，覺得店家很用...\n",
            "6204    旅行でラスベガスに来ましたがネイルがはげてるのが気になり、探したお店でした。\\n質問にも丁寧...\n",
            "6029    Just discovered this place, a hidden treasure ...\n",
            "4867    The ambiance of this place is a 4 or a 5- it's...\n",
            "4536    Burritos are on the \"smaller\" side but still g...\n",
            "5784    This is a great location. It's not as packed a...\n",
            "6290    Great place for a decent burrito.\\nLove the ca...\n",
            "721     ordered a spicy bbq steak burrito. add topping...\n",
            "4094    It's wonderful to find a coffee shop that care...\n",
            "822     Bomb tacos! Menu is simplistic, but food is al...\n",
            "Name: text, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLr-prhaGUjK",
        "colab_type": "text"
      },
      "source": [
        "## Part 3: Classification\n",
        "<a id=\"#p3\"></a>\n",
        "Your goal in this section will be to predict `stars` from the review dataset. \n",
        "\n",
        "1. Create a piepline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier. Use that pipeline to estimate a model to predict `stars`. Use the Pipeline to predict a star rating for your fake review from Part 2. \n",
        "2. Tune the entire pipeline with a GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ3sNt7QGUjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJdSb0iVGUjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect = TfidfVectorizer(stop_words='english')\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "pipe = Pipeline([('vect', vect), ('clf', clf)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytKj5g5gGUjg",
        "colab_type": "code",
        "colab": {},
        "outputId": "2463a970-148d-442b-8831-f6fca8799d1c"
      },
      "source": [
        "yelp.columns.to_list()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['business_id',\n",
              " 'cool',\n",
              " 'date',\n",
              " 'funny',\n",
              " 'review_id',\n",
              " 'stars',\n",
              " 'text',\n",
              " 'useful',\n",
              " 'user_id',\n",
              " 'text_tokens']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yx54k1_GUjp",
        "colab_type": "code",
        "colab": {},
        "outputId": "33530c26-1efe-4ebe-9324-a58f59e8362e"
      },
      "source": [
        "pipe.fit(yelp['text'], yelp['stars'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words='english', strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patte...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE8EL-MhGUjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bad_review = ['This place stinks, plain and simple. Worst calamari ever.']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q9hQTocGUj7",
        "colab_type": "code",
        "colab": {},
        "outputId": "b9459f76-958f-4904-d30c-e917c1e4ca82"
      },
      "source": [
        "pipe.predict(review)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7j04UhBGUkI",
        "colab_type": "code",
        "colab": {},
        "outputId": "9820c362-494d-4a22-d64d-6422f73adde5"
      },
      "source": [
        "pipe.predict(bad_review)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZi1D3jiGUkT",
        "colab_type": "code",
        "colab": {},
        "outputId": "fb46bde7-1578-4e9e-abf5-9fe24c833e28"
      },
      "source": [
        "parameters = {\n",
        "    'vect__max_df': (0.8, 0.9, 1.0),\n",
        "    'vect__min_df': (.02, .05, .1),\n",
        "#     'vect__max_features': (500,5000),\n",
        "    'clf__n_estimators': (50, 100),\n",
        "    'clf__max_depth': (20, 100, 200)\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipe, parameters, cv=3, n_jobs=4, verbose=1)\n",
        "grid_search.fit(yelp['text'], yelp['stars'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=4)]: Done 162 out of 162 | elapsed:  7.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vect',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words='english',\n",
              "                                                        strip...\n",
              "                                                               min_weight_fraction_leaf=0.0,\n",
              "                                                               n_estimators=100,\n",
              "                                                               n_jobs=None,\n",
              "                                                               oob_score=False,\n",
              "                                                               random_state=None,\n",
              "                                                               verbose=0,\n",
              "                                                               warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=4,\n",
              "             param_grid={'clf__max_depth': (20, 100, 200),\n",
              "                         'clf__n_estimators': (50, 100),\n",
              "                         'vect__max_df': (0.8, 0.9, 1.0),\n",
              "                         'vect__min_df': (0.02, 0.05, 0.1)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5WIq8KcGUkc",
        "colab_type": "code",
        "colab": {},
        "outputId": "b24c94f1-99b9-4a6e-97ec-7a2447ebe879"
      },
      "source": [
        "\n",
        "grid_search.predict(review)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbucfj0bGUkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_search.predict(bad_review)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9vCn3fWGUkw",
        "colab_type": "text"
      },
      "source": [
        "## Part 4: Topic Modeling\n",
        "\n",
        "Let's find out what those yelp reviews are saying! :D\n",
        "\n",
        "1. Estimate a LDA topic model of the review text\n",
        "    - Keep the `iterations` parameter at or below 5 to reduce run time\n",
        "    - The `workers` parameter should match the number of physical cores on your machine.\n",
        "2. Create 1-2 visualizations of the results\n",
        "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
        "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
        "\n",
        "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdq9nn-cGUky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import LdaMulticore\n",
        "from gensim.corpora import Dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5T_YW5eGUk6",
        "colab_type": "text"
      },
      "source": [
        "Learn the vocubalary of the yelp data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sTFXK2jGUk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word = Dictionary(yelp['text_tokens'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l50sFsbwGUlF",
        "colab_type": "code",
        "colab": {},
        "outputId": "3fea09a4-972c-423c-9530-cc66752f61d3"
      },
      "source": [
        "len(id2word.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arn2QoRJGUlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word.filter_extremes(no_below=5, no_above=0.95)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih73eqHaGUlc",
        "colab_type": "code",
        "colab": {},
        "outputId": "08ced6b1-5892-4200-c589-dbc05ee5831e"
      },
      "source": [
        "len(id2word.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10598"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wa3lun0GUli",
        "colab_type": "text"
      },
      "source": [
        "Create a bag of words representation of the entire corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDljptPNGUlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [id2word.doc2bow(tokens) for tokens in text_tokens]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmhyEzNXGUlo",
        "colab_type": "text"
      },
      "source": [
        "Your LDA model should be ready for estimation: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS-wB2dfGUlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda = LdaMulticore(corpus=corpus,\n",
        "                   id2word=id2word,\n",
        "                   iterations=5,\n",
        "                   workers=4,\n",
        "                   num_topics = 3 # You can change this parameter\n",
        "                  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMMTIKIbGUlx",
        "colab_type": "code",
        "colab": {},
        "outputId": "99d1a819-468d-4c09-afe2-5df91b1f68ed"
      },
      "source": [
        "lda.print_topics()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.009*\"place\" + 0.009*\"food\" + 0.009*\"like\" + 0.007*\"great\" + 0.006*\"good\" + 0.005*\"time\" + 0.005*\"it\\'s\" + 0.005*\"service\" + 0.004*\"don\\'t\" + 0.004*\"i\\'m\"'),\n",
              " (1,\n",
              "  '0.009*\"great\" + 0.008*\"food\" + 0.008*\"place\" + 0.008*\"like\" + 0.006*\"service\" + 0.006*\"time\" + 0.006*\"it\\'s\" + 0.005*\"good\" + 0.005*\"don\\'t\" + 0.004*\"love\"'),\n",
              " (2,\n",
              "  '0.008*\"good\" + 0.008*\"place\" + 0.007*\"it\\'s\" + 0.007*\"great\" + 0.007*\"food\" + 0.006*\"service\" + 0.005*\"time\" + 0.005*\"like\" + 0.004*\"didn\\'t\" + 0.004*\"best\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS7MUNXxGUl_",
        "colab_type": "text"
      },
      "source": [
        "Create 1-2 visualizations of the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFfb-kQUGUmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#visualize\n",
        "import re\n",
        "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Bn2t2ZGUmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topics = [' '.join(t[0:3]) for t in words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAVJXVU_GUmR",
        "colab_type": "code",
        "colab": {},
        "outputId": "5213a03c-355a-40a3-9857-06b44e66dda5"
      },
      "source": [
        "topics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['place food like', 'great food place', \"good place it's\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJlwrOCTGUmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyLDAvis.gensim\n",
        "\n",
        "pyLDAvis.enable_notebook()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOnXAofMGUmd",
        "colab_type": "code",
        "colab": {},
        "outputId": "e0b6f23c-f08f-4006-e5e1-ef72afddf527"
      },
      "source": [
        "pyLDAvis.gensim.prepare(lda, corpus, id2word)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1592826441412645841373306683\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1592826441412645841373306683_data = {\"mdsDat\": {\"x\": [0.003140574717016238, -0.004997824659812468, 0.0018572499427962307], \"y\": [0.003509940805098515, 0.0006570889818638149, -0.00416702978696233], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [33.41672134399414, 33.33259201049805, 33.25068664550781]}, \"tinfo\": {\"Term\": [\"like\", \"good\", \"i'm\", \"great\", \"feel\", \"didn't\", \"wait\", \"it's\", \"lot\", \"it.\", \"want\", \"find\", \"don't\", \"food\", \"friendly\", \"told\", \"service\", \"probably\", \"fun\", \"took\", \"customer\", \"mexican\", \"good.\", \"dinner\", \"you're\", \"delicious\", \"job\", \"sweet\", \"love\", \"new\", \"cant\", \"2016.\", \"bisque,\", \"1,\", \"smoothies.\", \"fooled\", \"appetizers\", \"done.\", \"dogs\", \"fruit\", \"chipotle\", \"swedish\", \"del\", \"job\", \"style.\", \"kitchen,\", \"mattress\", \"mexican\", \"extended\", \"us,\", \"themed\", \"rise\", \"kitchen\", \"bank,\", \"fruits.\", \"\\\"manager\\\"\", \"instructors\", \"warn\", \"waiter\", \"st\", \"attended\", \"mall\", \"fun\", \"mary\", \"feel\", \"felt\", \"patio\", \"owner\", \"rolls\", \"well,\", \"loves\", \"great\", \"took\", \"customer\", \"it.\", \"food.\", \"husband\", \"cheese\", \"point\", \"love\", \"bit\", \"i'm\", \"service\", \"don't\", \"happy\", \"time\", \"better\", \"like\", \"staff\", \"food\", \"dinner\", \"it's\", \"order\", \"place\", \"come\", \"went\", \"nice\", \"told\", \"restaurant\", \"minutes\", \"i've\", \"good\", \"little\", \"best\", \"know\", \"try\", \"didn't\", \"ordered\", \"people\", \"alien\", \"nick\", \"saves\", \"knowledgeable,\", \"pairing\", \"order,\", \"custard\", \"everyone,\", \"everyday,\", \"valentine's\", \"tremendous\", \"boxed\", \"loud,\", \"souvlaki\", \"worse\", \"it).\", \"adult\", \"latin\", \"compensate\", \"in\\\"\", \"scorpion\", \"wines\", \"stopping\", \"climb\", \"ago.\", \"often,\", \"josh\", \"strings\", \"tart.\", \"rare,\", \"appointment\", \"service,\", \"she's\", \"fine\", \"business.\", \"bc\", \"door\", \"dish.\", \"us.\", \"town.\", \"annoying\", \"bar,\", \"want\", \"delicious\", \"didn't\", \"good\", \"early\", \"fast\", \"friendly\", \"i'll\", \"ready\", \"simple\", \"new\", \"waiting\", \"it's\", \"wait\", \"stop\", \"gave\", \"ask\", \"probably\", \"know\", \"think\", \"told\", \"people\", \"pretty\", \"ordered\", \"worth\", \"service\", \"best\", \"big\", \"looking\", \"place\", \"time\", \"chicken\", \"i've\", \"can't\", \"great\", \"nice\", \"recommend\", \"come\", \"food\", \"love\", \"order\", \"little\", \"staff\", \"like\", \"don't\", \"went\", \"try\", \"do,\", \"legs\", \"code\", \"city.\", \"easy\", \"right!\", \"onions,\", \"(in\", \"eggs\", \"200\", \"vehicle\", \"(2)\", \"convenience\", \"scallops\", \"palate\", \"unfortunately,\", \"stylist\", \"hell\", \"world,\", \"pancake\", \"umbrella\", \"installer\", \"diego\", \"try.\", \"'em\", \"customers,\", \"convenient\", \"warned\", \"warmly\", \"nicole\", \"lot\", \"great,\", \"french\", \"moved\", \"read\", \"actual\", \"find\", \"restaurant.\", \"chips\", \"makes\", \"like\", \"you're\", \"guess\", \"flavor\", \"night\", \"food\", \"working\", \"place\", \"try\", \"good.\", \"i'm\", \"price\", \"eat\", \"portion\", \"went\", \"times\", \"cooked\", \"clean\", \"don't\", \"chicken\", \"little\", \"asked\", \"good\", \"thing\", \"highly\", \"ordered\", \"best\", \"great\", \"wait\", \"menu\", \"time\", \"it.\", \"i've\", \"recommend\", \"service\", \"it's\", \"pretty\", \"come\", \"nice\", \"love\", \"didn't\", \"people\", \"staff\", \"order\"], \"Freq\": [3237.0, 3039.0, 1524.0, 3359.0, 632.0, 1480.0, 811.0, 2612.0, 694.0, 1132.0, 960.0, 754.0, 1777.0, 3554.0, 895.0, 939.0, 2526.0, 439.0, 322.0, 903.0, 750.0, 213.0, 825.0, 461.0, 626.0, 523.0, 309.0, 466.0, 1550.0, 1062.0, 25.521194458007812, 4.9449567794799805, 3.096970319747925, 4.800863265991211, 2.9880549907684326, 3.672250986099243, 48.03762435913086, 56.698028564453125, 43.48058319091797, 36.167266845703125, 14.414703369140625, 3.6658339500427246, 8.503094673156738, 151.7696075439453, 12.065040588378906, 10.144269943237305, 4.261412620544434, 103.4850845336914, 13.190159797668457, 38.41291809082031, 6.6208720207214355, 2.7615063190460205, 75.9511947631836, 3.481247901916504, 4.935878753662109, 3.477994680404663, 10.606001853942871, 7.531429767608643, 117.49738311767578, 9.618060111999512, 12.439797401428223, 42.64766311645508, 150.0723114013672, 13.825177192687988, 289.4952087402344, 154.3873748779297, 68.28291320800781, 143.27850341796875, 81.69530487060547, 91.72116088867188, 40.0764274597168, 1366.98291015625, 386.8063049316406, 322.99676513671875, 470.971435546875, 274.1837463378906, 163.80514526367188, 236.29537963867188, 91.58867645263672, 610.1343383789062, 316.91741943359375, 596.9751586914062, 949.7222900390625, 684.370849609375, 252.93946838378906, 901.6978149414062, 353.765869140625, 1145.5919189453125, 472.3362121582031, 1224.0418701171875, 192.30670166015625, 891.289794921875, 434.79266357421875, 1176.601806640625, 507.93292236328125, 508.9526672363281, 472.1091003417969, 349.0201416015625, 350.61029052734375, 269.6333923339844, 482.9486389160156, 799.2798461914062, 441.49652099609375, 481.6537780761719, 367.0209045410156, 394.9388122558594, 440.0159606933594, 394.1186218261719, 355.09185791015625, 5.047232151031494, 8.774420738220215, 3.0240695476531982, 16.296297073364258, 5.437368392944336, 44.35527038574219, 11.600095748901367, 3.5832953453063965, 4.404126167297363, 9.27811336517334, 5.2794508934021, 2.8780555725097656, 8.234163284301758, 3.1111302375793457, 35.49386215209961, 9.259723663330078, 12.030784606933594, 8.240639686584473, 3.820064067840576, 5.27433443069458, 3.0807437896728516, 27.257497787475586, 17.099218368530273, 4.51782751083374, 33.96036911010742, 6.5364155769348145, 10.155661582946777, 3.4577319622039795, 2.809852123260498, 4.814864158630371, 111.68861389160156, 113.41378784179688, 36.844722747802734, 71.00708770751953, 40.401641845703125, 15.952970504760742, 92.01512145996094, 34.674705505371094, 107.78825378417969, 63.89045715332031, 16.973093032836914, 48.80333709716797, 424.28509521484375, 234.1156768798828, 637.7982177734375, 1271.6536865234375, 76.35851287841797, 128.05935668945312, 386.3262023925781, 180.86485290527344, 83.73515319824219, 78.40159606933594, 440.3657531738281, 172.1728973388672, 1016.045166015625, 334.66015625, 141.63009643554688, 199.18862915039062, 194.8834991455078, 183.75364685058594, 423.8636779785156, 332.9776916503906, 369.3219909667969, 447.50372314453125, 396.61737060546875, 532.87451171875, 249.60911560058594, 887.1011352539062, 585.578857421875, 237.68826293945312, 264.3023986816406, 1169.4544677734375, 810.5331420898438, 417.0761413574219, 522.0553588867188, 298.69403076171875, 1010.2445068359375, 466.081787109375, 377.9111633300781, 479.0101318359375, 1004.1385498046875, 514.8074951171875, 396.6938171386719, 452.4075927734375, 406.6960144042969, 784.4860229492188, 458.7772216796875, 383.7985534667969, 349.0518798828125, 15.039633750915527, 18.978904724121094, 12.139952659606934, 27.795217514038086, 114.20657348632812, 14.143799781799316, 16.79071044921875, 14.966952323913574, 76.57184600830078, 5.465605735778809, 32.34367370605469, 3.242902994155884, 9.586479187011719, 20.652881622314453, 6.388641834259033, 22.746612548828125, 23.82697296142578, 26.767742156982422, 7.640374660491943, 11.504107475280762, 3.194525718688965, 2.1216671466827393, 5.237382888793945, 54.57555389404297, 4.543255805969238, 12.999381065368652, 33.5807991027832, 16.54228401184082, 6.634865760803223, 5.16684627532959, 322.8492736816406, 110.49043273925781, 81.57746887207031, 77.10700225830078, 68.2367172241211, 45.78718566894531, 333.66656494140625, 105.63998413085938, 79.33826446533203, 138.06210327148438, 1307.1014404296875, 268.9792175292969, 92.3991470336914, 130.1118621826172, 247.42234802246094, 1326.5618896484375, 114.56697082519531, 1338.98974609375, 479.2900695800781, 331.52178955078125, 579.55615234375, 239.07754516601562, 285.8367004394531, 82.40369415283203, 529.7376708984375, 246.03578186035156, 142.65773010253906, 191.0688018798828, 634.2086791992188, 422.40447998046875, 507.16632080078125, 303.9976501464844, 968.7328491210938, 204.89796447753906, 212.75660705566406, 492.83892822265625, 538.3941040039062, 981.800048828125, 300.6412353515625, 309.928466796875, 732.2988891601562, 388.5334167480469, 478.1243896484375, 357.02581787109375, 689.2841186523438, 704.9909057617188, 345.7907409667969, 420.19915771484375, 400.1595764160156, 425.3702087402344, 402.8865661621094, 358.54827880859375, 353.4605712890625, 329.2777404785156], \"Total\": [3237.0, 3039.0, 1524.0, 3359.0, 632.0, 1480.0, 811.0, 2612.0, 694.0, 1132.0, 960.0, 754.0, 1777.0, 3554.0, 895.0, 939.0, 2526.0, 439.0, 322.0, 903.0, 750.0, 213.0, 825.0, 461.0, 626.0, 523.0, 309.0, 466.0, 1550.0, 1062.0, 45.348731994628906, 8.895979881286621, 5.8807477951049805, 9.426593780517578, 5.879948616027832, 7.241211414337158, 95.06067657470703, 112.5987548828125, 87.0910873413086, 72.81439208984375, 29.03800392150879, 7.39239501953125, 17.20413589477539, 309.8228759765625, 24.632492065429688, 20.743213653564453, 8.754669189453125, 213.0770721435547, 27.167634963989258, 79.2757339477539, 13.671098709106445, 5.724428653717041, 157.5047607421875, 7.230518817901611, 10.266985893249512, 7.244811058044434, 22.099742889404297, 15.694550514221191, 245.08563232421875, 20.080509185791016, 25.976947784423828, 90.44886779785156, 322.61517333984375, 29.05029296875, 632.7789916992188, 333.1958312988281, 145.82684326171875, 313.93426513671875, 178.17050170898438, 201.0345458984375, 86.5234375, 3359.027587890625, 903.755859375, 750.5026245117188, 1132.8109130859375, 649.2205200195312, 378.7927551269531, 560.759033203125, 207.8146209716797, 1550.3121337890625, 774.6425170898438, 1524.1923828125, 2526.107666015625, 1777.356689453125, 612.6746215820312, 2444.52978515625, 889.2071533203125, 3237.17919921875, 1232.4927978515625, 3554.7421875, 461.75128173828125, 2612.325927734375, 1160.76416015625, 3685.0458984375, 1407.1422119140625, 1422.4888916015625, 1338.3504638671875, 939.0816650390625, 959.4384765625, 694.223388671875, 1483.12841796875, 3039.66650390625, 1401.0704345703125, 1605.626708984375, 1083.6253662109375, 1223.28076171875, 1480.7008056640625, 1419.83203125, 1161.143798828125, 9.62066650390625, 16.751296997070312, 5.915122985839844, 32.1412353515625, 10.82447338104248, 89.1344985961914, 23.39598274230957, 7.258921146392822, 8.945220947265625, 18.965707778930664, 10.803955078125, 5.907068252563477, 16.965272903442383, 6.425551414489746, 73.35977172851562, 19.14364242553711, 24.88699722290039, 17.112648010253906, 7.937283515930176, 10.968175888061523, 6.41429328918457, 56.86482238769531, 35.74493408203125, 9.460427284240723, 71.1188735961914, 13.698488235473633, 21.29380989074707, 7.255186557769775, 5.902655601501465, 10.139106750488281, 238.9833221435547, 243.2792205810547, 78.14817810058594, 151.65489196777344, 85.9167709350586, 33.693084716796875, 197.8695068359375, 73.94197845458984, 235.58541870117188, 138.73915100097656, 35.889583587646484, 105.4476547241211, 960.9935913085938, 523.463623046875, 1480.7008056640625, 3039.66650390625, 167.8956298828125, 286.36151123046875, 895.5716552734375, 414.5763244628906, 186.259033203125, 174.06301879882812, 1062.527099609375, 398.8806457519531, 2612.325927734375, 811.5532836914062, 326.3363342285156, 472.5525207519531, 461.6551208496094, 439.57891845703125, 1083.6253662109375, 834.7544555664062, 939.0816650390625, 1161.143798828125, 1018.620849609375, 1419.83203125, 619.9924926757812, 2526.107666015625, 1605.626708984375, 590.9817504882812, 667.6796264648438, 3685.0458984375, 2444.52978515625, 1135.47265625, 1483.12841796875, 772.768798828125, 3359.027587890625, 1338.3504638671875, 1041.457763671875, 1407.1422119140625, 3554.7421875, 1550.3121337890625, 1160.76416015625, 1401.0704345703125, 1232.4927978515625, 3237.17919921875, 1777.356689453125, 1422.4888916015625, 1223.28076171875, 28.093637466430664, 36.40106964111328, 23.313976287841797, 53.53545379638672, 224.9931182861328, 28.032527923583984, 33.32664108276367, 29.770832061767578, 154.20492553710938, 11.01439380645752, 65.51649475097656, 6.6074934005737305, 19.560440063476562, 42.1470832824707, 13.056732177734375, 46.57962417602539, 48.79307174682617, 55.20894241333008, 15.782257080078125, 23.771440505981445, 6.609060764312744, 4.395633697509766, 10.851701736450195, 113.74375915527344, 9.488682746887207, 27.173377990722656, 70.23309326171875, 34.627235412597656, 13.892337799072266, 10.84745979309082, 694.996337890625, 237.50448608398438, 175.9990234375, 166.5772705078125, 147.12969970703125, 97.96419525146484, 754.9317626953125, 231.38511657714844, 174.49057006835938, 311.27703857421875, 3237.17919921875, 626.2591552734375, 207.13540649414062, 297.86236572265625, 586.3843994140625, 3554.7421875, 260.9437255859375, 3685.0458984375, 1223.28076171875, 825.58984375, 1524.1923828125, 583.3583984375, 709.953857421875, 185.13226318359375, 1422.4888916015625, 613.7864990234375, 337.99969482421875, 468.13763427734375, 1777.356689453125, 1135.47265625, 1401.0704345703125, 793.6597900390625, 3039.66650390625, 511.7386474609375, 534.531005859375, 1419.83203125, 1605.626708984375, 3359.027587890625, 811.5532836914062, 843.7716064453125, 2444.52978515625, 1132.8109130859375, 1483.12841796875, 1041.457763671875, 2526.107666015625, 2612.325927734375, 1018.620849609375, 1407.1422119140625, 1338.3504638671875, 1550.3121337890625, 1480.7008056640625, 1161.143798828125, 1232.4927978515625, 1160.76416015625], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -8.679699897766113, -10.320799827575684, -10.788700103759766, -10.3503999710083, -10.82450008392334, -10.618399620056152, -8.047200202941895, -7.881400108337402, -8.14680004119873, -8.331000328063965, -9.250900268554688, -10.620100021362305, -9.77869987487793, -6.8968000411987305, -9.428799629211426, -9.602299690246582, -10.469599723815918, -7.279699802398682, -9.339699745178223, -8.27079963684082, -10.028900146484375, -10.903400421142578, -7.589099884033203, -10.671799659729004, -10.322600364685059, -10.672699928283691, -9.557700157165527, -9.900099754333496, -7.152699947357178, -9.655500411987305, -9.398300170898438, -8.166199684143066, -6.9079999923706055, -9.292699813842773, -6.250999927520752, -6.879700183868408, -7.695499897003174, -6.954400062561035, -7.516200065612793, -7.400400161743164, -8.228400230407715, -4.698800086975098, -5.96120023727417, -6.141499996185303, -5.764400005340576, -6.3053998947143555, -6.820499897003174, -6.454100131988525, -7.401899814605713, -5.505499839782715, -6.1605000495910645, -5.527299880981445, -5.063000202178955, -5.390699863433838, -6.386000156402588, -5.1149001121521, -6.05049991607666, -4.875500202178955, -5.761499881744385, -4.809199810028076, -6.660099983215332, -5.126500129699707, -5.844299793243408, -4.848800182342529, -5.688799858093262, -5.686800003051758, -5.76200008392334, -6.064000129699707, -6.059500217437744, -6.3221001625061035, -5.739200115203857, -5.235400199890137, -5.828999996185303, -5.7418999671936035, -6.013700008392334, -5.940400123596191, -5.832300186157227, -5.942500114440918, -6.046800136566162, -10.297800064086914, -9.744799613952637, -10.8100004196167, -9.125699996948242, -10.223299980163574, -8.12440013885498, -9.46560001373291, -10.640399932861328, -10.434100151062012, -9.689000129699707, -10.252799987792969, -10.85949993133545, -9.808300018310547, -10.781700134277344, -8.347299575805664, -9.690999984741211, -9.429200172424316, -9.807600021362305, -10.576399803161621, -10.253800392150879, -10.791500091552734, -8.611300468444824, -9.07759952545166, -10.408599853515625, -8.391400337219238, -10.039299964904785, -9.598600387573242, -10.675999641418457, -10.883500099182129, -10.344900131225586, -7.200900077819824, -7.1855998039245605, -8.309900283813477, -7.653900146484375, -8.21780014038086, -9.147000312805176, -7.394700050354004, -8.370599746704102, -7.236499786376953, -7.759500026702881, -9.085000038146973, -8.028800010681152, -5.866199970245361, -6.4608001708984375, -5.458600044250488, -4.768599987030029, -7.581200122833252, -7.0640997886657715, -5.960000038146973, -6.718900203704834, -7.488999843597412, -7.554800033569336, -5.828999996185303, -6.768099784851074, -4.993000030517578, -6.103499889373779, -6.963399887084961, -6.622399806976318, -6.644199848175049, -6.703000068664551, -5.867199897766113, -6.10860013961792, -6.005000114440918, -5.813000202178955, -5.933700084686279, -5.638400077819824, -6.396699905395508, -5.128699779510498, -5.544000148773193, -6.445700168609619, -6.3394999504089355, -4.85230016708374, -5.218900203704834, -5.883399963378906, -5.658899784088135, -6.217199802398682, -4.998700141906738, -5.772299766540527, -5.98199987411499, -5.744900226593018, -5.004799842834473, -5.672800064086914, -5.933499813079834, -5.80210018157959, -5.908599853515625, -5.2515997886657715, -5.788099765777588, -5.9664998054504395, -6.061399936676025, -9.203499794006348, -8.97089958190918, -9.417699813842773, -8.589300155639648, -7.176199913024902, -9.264900207519531, -9.093400001525879, -9.20829963684082, -7.576000213623047, -10.215700149536133, -8.437800407409668, -10.737700462341309, -9.653800010681152, -8.886300086975098, -10.059700012207031, -8.789799690246582, -8.743399620056152, -8.626999855041504, -9.88070011138916, -9.471500396728516, -10.752699851989746, -11.161999702453613, -10.258399963378906, -7.914599895477295, -10.400500297546387, -9.349300384521484, -8.400199890136719, -9.10830020904541, -10.02180004119873, -10.271900177001953, -6.13700008392334, -7.2093000411987305, -7.512599945068359, -7.568999767303467, -7.691199779510498, -8.090200424194336, -6.104000091552734, -7.2540998458862305, -7.540500164031982, -6.986499786376953, -4.73859977722168, -6.319499969482422, -7.3881001472473145, -7.04580020904541, -6.40310001373291, -4.723800182342529, -7.172999858856201, -4.7144999504089355, -5.7418999671936035, -6.110499858856201, -5.5518999099731445, -6.437399864196777, -6.258800029754639, -7.502500057220459, -5.6417999267578125, -6.408699989318848, -6.953700065612793, -6.661499977111816, -5.4618000984191895, -5.868199825286865, -5.685299873352051, -6.197199821472168, -5.0381999015808105, -6.591700077056885, -6.553999900817871, -5.714000225067139, -5.6255998611450195, -5.024799823760986, -6.2083001136779785, -6.177800178527832, -5.317999839782715, -5.9517998695373535, -5.74429988861084, -6.036399841308594, -5.378499984741211, -5.355999946594238, -6.068299770355225, -5.873499870300293, -5.922299861907959, -5.861199855804443, -5.915500164031982, -6.032100200653076, -6.04640007019043, -6.117300033569336], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.5212000012397766, 0.508899986743927, 0.45489999651908875, 0.4214000105857849, 0.41920000314712524, 0.4171000123023987, 0.41359999775886536, 0.4099999964237213, 0.40149998664855957, 0.39640000462532043, 0.39579999446868896, 0.39469999074935913, 0.391400009393692, 0.3824999928474426, 0.3824000060558319, 0.3808000087738037, 0.37610000371932983, 0.37389999628067017, 0.3736000061035156, 0.3716000020503998, 0.3711000084877014, 0.3671000003814697, 0.3666999936103821, 0.365200012922287, 0.3637000024318695, 0.36230000853538513, 0.3619999885559082, 0.3619000017642975, 0.36090001463890076, 0.36000001430511475, 0.3598000109195709, 0.3443000018596649, 0.33079999685287476, 0.35359999537467957, 0.3140999972820282, 0.32679998874664307, 0.33739998936653137, 0.3116999864578247, 0.3163999915122986, 0.31139999628067017, 0.3264999985694885, 0.19709999859333038, 0.2475000023841858, 0.2529999911785126, 0.21850000321865082, 0.23409999907016754, 0.25780001282691956, 0.23190000653266907, 0.2768000066280365, 0.16359999775886536, 0.20239999890327454, 0.15880000591278076, 0.11779999732971191, 0.14169999957084656, 0.21140000224113464, 0.09880000352859497, 0.17440000176429749, 0.05730000138282776, 0.13699999451637268, 0.029999999329447746, 0.22020000219345093, 0.020800000056624413, 0.11410000175237656, -0.045499999076128006, 0.0771000012755394, 0.06830000132322311, 0.054099999368190765, 0.1062999963760376, 0.08940000087022781, 0.15039999783039093, -0.02590000070631504, -0.23970000445842743, -0.05869999900460243, -0.10790000110864639, 0.013500000350177288, -0.03440000116825104, -0.11729999631643295, -0.18549999594688416, -0.08869999647140503, 0.4535999894142151, 0.4519999921321869, 0.427700012922287, 0.41940000653266907, 0.4101000130176544, 0.40070000290870667, 0.3971000015735626, 0.3926999866962433, 0.39010000228881836, 0.38370001316070557, 0.3824999928474426, 0.37959998846054077, 0.3758000135421753, 0.3732999861240387, 0.3725999891757965, 0.37229999899864197, 0.3718000054359436, 0.367900013923645, 0.36730000376701355, 0.36649999022483826, 0.3652999997138977, 0.36329999566078186, 0.361299991607666, 0.359499990940094, 0.359499990940094, 0.3587000072002411, 0.3582000136375427, 0.35749998688697815, 0.3564000129699707, 0.3538999855518341, 0.33799999952316284, 0.33550000190734863, 0.3467000126838684, 0.33980000019073486, 0.3440999984741211, 0.35100001096725464, 0.3330000042915344, 0.34139999747276306, 0.3167000114917755, 0.323199987411499, 0.3497999906539917, 0.32820001244544983, 0.28110000491142273, 0.2939999997615814, 0.2563999891281128, 0.2272000014781952, 0.310699999332428, 0.2939000129699707, 0.2578999996185303, 0.26910001039505005, 0.29919999837875366, 0.3010999858379364, 0.21780000627040863, 0.25850000977516174, 0.1543000042438507, 0.21279999613761902, 0.2639000117778778, 0.23469999432563782, 0.2362000048160553, 0.2264000028371811, 0.1599999964237213, 0.17960000038146973, 0.16539999842643738, 0.1451999992132187, 0.15539999306201935, 0.11860000342130661, 0.18880000710487366, 0.05220000073313713, 0.09000000357627869, 0.18780000507831573, 0.17190000414848328, -0.04910000041127205, -0.0052999998442828655, 0.09709999710321426, 0.054499998688697815, 0.14810000360012054, -0.10279999673366547, 0.043800000101327896, 0.08489999920129776, 0.020999999716877937, -0.1655000001192093, -0.003800000064074993, 0.02500000037252903, -0.03180000185966492, -0.010099999606609344, -0.3188000023365021, -0.2556999921798706, -0.21140000224113464, -0.15539999306201935, 0.47620001435279846, 0.4498000144958496, 0.44850000739097595, 0.4456000030040741, 0.4230000078678131, 0.4169999957084656, 0.4156000018119812, 0.41339999437332153, 0.4009999930858612, 0.4004000127315521, 0.3952000141143799, 0.38940000534057617, 0.3878999948501587, 0.387800008058548, 0.3862999975681305, 0.38429999351501465, 0.38429999351501465, 0.37720000743865967, 0.3756999969482422, 0.37529999017715454, 0.374099999666214, 0.3727000057697296, 0.3725999891757965, 0.3666999936103821, 0.3646000027656555, 0.3637999892234802, 0.36320000886917114, 0.36239999532699585, 0.3621000051498413, 0.3594000041484833, 0.3343999981880188, 0.3357999920845032, 0.33219999074935913, 0.33079999685287476, 0.3328000009059906, 0.34049999713897705, 0.28459998965263367, 0.31700000166893005, 0.31290000677108765, 0.288100004196167, 0.19419999420642853, 0.25600001215934753, 0.2937999963760376, 0.2728999853134155, 0.23819999396800995, 0.11540000140666962, 0.27790001034736633, 0.08869999647140503, 0.16410000622272491, 0.18870000541210175, 0.13410000503063202, 0.20909999310970306, 0.19130000472068787, 0.29170000553131104, 0.11330000311136246, 0.18690000474452972, 0.23849999904632568, 0.20499999821186066, 0.0706000030040741, 0.11230000108480453, 0.08489999920129776, 0.14149999618530273, -0.042399998754262924, 0.1858000010251999, 0.17990000545978546, 0.0430000014603138, 0.00839999970048666, -0.12890000641345978, 0.10809999704360962, 0.09960000216960907, -0.10429999977350235, 0.03099999949336052, -0.030899999663233757, 0.030500000342726707, -0.19769999384880066, -0.2087000012397766, 0.02070000022649765, -0.10750000178813934, -0.10620000213384628, -0.19220000505447388, -0.2004999965429306, -0.07400000095367432, -0.14790000021457672, -0.15880000591278076]}, \"token.table\": {\"Topic\": [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3], \"Freq\": [0.41408947110176086, 0.27605965733528137, 0.27605965733528137, 0.2107774168252945, 0.2107774168252945, 0.5269435048103333, 0.3026866316795349, 0.3026866316795349, 0.45402997732162476, 0.201539546251297, 0.3023093342781067, 0.5038488507270813, 0.5304142832756042, 0.2121657133102417, 0.2121657133102417, 0.2723708748817444, 0.1815805733203888, 0.4539514482021332, 0.5620516538619995, 0.22482065856456757, 0.22482065856456757, 0.30623432993888855, 0.2245718389749527, 0.46955931186676025, 0.24108974635601044, 0.4821794927120209, 0.281271368265152, 0.2109144777059555, 0.4780728220939636, 0.3093412220478058, 0.20788580179214478, 0.5197145342826843, 0.20788580179214478, 0.25076913833618164, 0.47367504239082336, 0.27863237261772156, 0.5049406290054321, 0.26298990845680237, 0.23143112659454346, 0.23432597517967224, 0.4686519503593445, 0.3012762665748596, 0.3119211494922638, 0.42239323258399963, 0.2642665505409241, 0.35027602314949036, 0.2658569812774658, 0.38303565979003906, 0.461948037147522, 0.269469678401947, 0.230974018573761, 0.4149079918861389, 0.2766053378582001, 0.13830266892910004, 0.2939847409725189, 0.4646855294704437, 0.24656783044338226, 0.2967967987060547, 0.474874883890152, 0.237437441945076, 0.30019432306289673, 0.3649665117263794, 0.3350716531276703, 0.39810746908187866, 0.3058904707431793, 0.2957690954208374, 0.2707359492778778, 0.4027197062969208, 0.32657521963119507, 0.5101392269134521, 0.17004640400409698, 0.17004640400409698, 0.40922102332115173, 0.3266022503376007, 0.26463818550109863, 0.16928870975971222, 0.5078661441802979, 0.33857741951942444, 0.2677009403705597, 0.46556684374809265, 0.2677009403705597, 0.2795144021511078, 0.38692039251327515, 0.3338644206523895, 0.5733346343040466, 0.24256466329097748, 0.19846199452877045, 0.42085814476013184, 0.27462777495384216, 0.30494382977485657, 0.26068440079689026, 0.36724793910980225, 0.37165141105651855, 0.48212680220603943, 0.24106340110301971, 0.24106340110301971, 0.2120458483695984, 0.33239617943763733, 0.45274654030799866, 0.2801881432533264, 0.18679210543632507, 0.5230178833007812, 0.32255470752716064, 0.26915162801742554, 0.4079996645450592, 0.21140694618225098, 0.5285173654556274, 0.31711041927337646, 0.21446363627910614, 0.25735634565353394, 0.5147126913070679, 0.3610153794288635, 0.34040623903274536, 0.29847729206085205, 0.2519753873348236, 0.5039507746696472, 0.2519753873348236, 0.25561797618865967, 0.25561797618865967, 0.5112359523773193, 0.2420511394739151, 0.2847660481929779, 0.4841022789478302, 0.2544381022453308, 0.3254440724849701, 0.4230773150920868, 0.2137119024991989, 0.5129085779190063, 0.29919666051864624, 0.4303782284259796, 0.313123494386673, 0.2571609914302826, 0.2208043485879898, 0.2944057881832123, 0.47840940952301025, 0.5231299996376038, 0.23250223696231842, 0.29062777757644653, 0.25025618076324463, 0.4470224678516388, 0.30183568596839905, 0.29715660214424133, 0.43087705969810486, 0.27216842770576477, 0.2764543294906616, 0.2764543294906616, 0.46075722575187683, 0.4158082604408264, 0.21440114080905914, 0.3681635558605194, 0.2434341162443161, 0.4733441174030304, 0.2840064764022827, 0.24916674196720123, 0.2135714888572693, 0.5339287519454956, 0.4937359392642975, 0.1722334623336792, 0.33298471570014954, 0.3848411440849304, 0.2582486569881439, 0.35670948028564453, 0.5062223076820374, 0.19538404047489166, 0.2930760681629181, 0.23753027617931366, 0.46495288610458374, 0.29312247037887573, 0.28589189052581787, 0.4526621699333191, 0.262067586183548, 0.23111818730831146, 0.26223024725914, 0.5066821575164795, 0.31692200899124146, 0.2802999019622803, 0.40284308791160583, 0.3047892153263092, 0.19454631209373474, 0.49933552742004395, 0.22358307242393494, 0.4471661448478699, 0.22358307242393494, 0.27552303671836853, 0.5510460734367371, 0.27552303671836853, 0.4785105586051941, 0.25765952467918396, 0.25765952467918396, 0.23746207356452942, 0.44698745012283325, 0.31428804993629456, 0.45671555399894714, 0.2007019817829132, 0.34293174743652344, 0.4621906578540802, 0.22509285807609558, 0.3121287524700165, 0.3245326280593872, 0.23313365876674652, 0.44242408871650696, 0.2769445776939392, 0.4681682288646698, 0.25716280937194824, 0.33236828446388245, 0.23165062069892883, 0.43644317984580994, 0.34432876110076904, 0.28243961930274963, 0.373304158449173, 0.422044575214386, 0.3173035979270935, 0.26031216979026794, 0.5523937344551086, 0.2761968672275543, 0.2761968672275543, 0.24431954324245453, 0.2897743284702301, 0.4659116864204407, 0.2534693777561188, 0.4310096204280853, 0.31599926948547363, 0.4944077432155609, 0.2609374225139618, 0.24720387160778046, 0.4869978427886963, 0.29219871759414673, 0.19479914009571075, 0.46495023369789124, 0.3471628427505493, 0.18598009645938873, 0.24124301970005035, 0.42111721634864807, 0.3364705443382263, 0.2628577947616577, 0.4184669554233551, 0.3187849819660187, 0.35247525572776794, 0.24588480591773987, 0.40213674306869507, 0.4069630205631256, 0.3006822466850281, 0.2923465073108673, 0.2905208170413971, 0.24420590698719025, 0.46314916014671326, 0.27518230676651, 0.28001007437705994, 0.44415390491485596, 0.4129434823989868, 0.33786284923553467, 0.24972471594810486, 0.2716951072216034, 0.2535821199417114, 0.4890512228012085, 0.2806198298931122, 0.3217774033546448, 0.3984801471233368, 0.43295443058013916, 0.25079676508903503, 0.3167959153652191, 0.26050692796707153, 0.4365902841091156, 0.3039247393608093, 0.39168283343315125, 0.22831763327121735, 0.38052940368652344, 0.3256629705429077, 0.3519587218761444, 0.32229170203208923, 0.2735185921192169, 0.4558643102645874, 0.18234573304653168, 0.22749848663806915, 0.22749848663806915, 0.4549969732761383, 0.4977433383464813, 0.27149638533592224, 0.22624698281288147, 0.3410753607749939, 0.3889254331588745, 0.2698744535446167, 0.20894664525985718, 0.47012996673583984, 0.31341996788978577, 0.41577988862991333, 0.2409934401512146, 0.34339359402656555, 0.49060288071632385, 0.26789501309394836, 0.24207380414009094, 0.32873404026031494, 0.4696200489997864, 0.1878480166196823, 0.482525110244751, 0.2730076313018799, 0.24761156737804413, 0.48208537697792053, 0.2892512381076813, 0.24104268848896027, 0.33867794275283813, 0.3912791311740875, 0.270388662815094, 0.24890144169330597, 0.49780288338661194, 0.24890144169330597, 0.23374523222446442, 0.46749046444892883, 0.2921815514564514, 0.3021889328956604, 0.16483032703399658, 0.5219627022743225, 0.3540119230747223, 0.24218615889549255, 0.4037465751171112, 0.31475934386253357, 0.322610467672348, 0.36186617612838745, 0.26659491658210754, 0.39539921283721924, 0.3369879722595215, 0.2575553059577942, 0.27913814783096313, 0.46475064754486084, 0.17683181166648865, 0.4715515077114105, 0.3536636233329773, 0.3934691548347473, 0.3321911692619324, 0.27413833141326904, 0.46230247616767883, 0.28893905878067017, 0.2542663514614105, 0.22809264063835144, 0.32768237590789795, 0.4433349668979645, 0.4754067361354828, 0.24323134124279022, 0.2874552309513092, 0.48192286491394043, 0.24096143245697021, 0.27538448572158813, 0.4568990468978882, 0.2284495234489441, 0.2284495234489441, 0.264289528131485, 0.36858314275741577, 0.3673979938030243, 0.4833931624889374, 0.3425990343093872, 0.16895295679569244, 0.3889237940311432, 0.3169008791446686, 0.29529398679733276, 0.21011270582675934, 0.32417386770248413, 0.46224793791770935, 0.2964630126953125, 0.414107084274292, 0.28893381357192993, 0.3526729345321655, 0.3481898009777069, 0.2988753914833069, 0.17909060418605804, 0.5372718572616577, 0.29848435521125793, 0.2765624523162842, 0.2765624523162842, 0.46093741059303284, 0.32401952147483826, 0.2540995180606842, 0.4212253987789154, 0.2920030355453491, 0.5110052824020386, 0.2920030355453491, 0.24004819989204407, 0.2700542211532593, 0.510102391242981, 0.37475311756134033, 0.3420160710811615, 0.2834339737892151, 0.24681802093982697, 0.49363604187965393, 0.2580370008945465, 0.27749761939048767, 0.3753965198993683, 0.3472241759300232, 0.45550936460494995, 0.26757192611694336, 0.27712807059288025, 0.2771497368812561, 0.4619162380695343, 0.2771497368812561, 0.306355357170105, 0.22976653277873993, 0.45953306555747986, 0.25240370631217957, 0.25240370631217957, 0.5048074126243591, 0.4663064777851105, 0.2194383442401886, 0.31544262170791626, 0.3057330250740051, 0.3858264684677124, 0.3091779053211212, 0.31939899921417236, 0.3172280788421631, 0.3633604645729065, 0.4427022337913513, 0.3224027156829834, 0.2357870638370514, 0.29708489775657654, 0.25927409529685974, 0.4429265856742859, 0.27095460891723633, 0.3897426724433899, 0.3396749496459961, 0.32398608326911926, 0.26570287346839905, 0.40969666838645935, 0.386733740568161, 0.41858240962028503, 0.19564177095890045, 0.29588404297828674, 0.4931401014328003, 0.29588404297828674, 0.2650722563266754, 0.2650722563266754, 0.46217724680900574, 0.24159902334213257, 0.4509848356246948, 0.3060254156589508, 0.29477912187576294, 0.3629527986049652, 0.3427887558937073, 0.3658389747142792, 0.3283170461654663, 0.3064292371273041, 0.2982041537761688, 0.24202075600624084, 0.4581107199192047, 0.21403706073760986, 0.24970990419387817, 0.49941980838775635, 0.5240697860717773, 0.17468991875648499, 0.17468991875648499, 0.46023330092430115, 0.20766624808311462, 0.33114346861839294, 0.1690581887960434, 0.507174551486969, 0.3381163775920868, 0.26099076867103577, 0.26099076867103577, 0.4982551336288452, 0.3118036389350891, 0.46770545840263367, 0.15590181946754456, 0.37607264518737793, 0.3511331081390381, 0.2727516293525696, 0.3165087401866913, 0.46448686718940735, 0.21785666048526764, 0.21753546595573425, 0.47345954179763794, 0.30710887908935547, 0.2929973304271698, 0.4481135606765747, 0.25278201699256897, 0.5102085471153259, 0.3401390314102173, 0.17006951570510864, 0.15562866628170013, 0.4668860137462616, 0.31125733256340027, 0.4979953467845917, 0.24899767339229584, 0.24899767339229584, 0.3829636871814728, 0.33022505044937134, 0.2864114046096802, 0.2849820554256439, 0.4351339042186737, 0.2788534164428711, 0.2238079309463501, 0.47559186816215515, 0.2797599136829376, 0.2756648659706116, 0.41349729895591736, 0.2756648659706116, 0.48716142773628235, 0.2841775119304657, 0.20298393070697784, 0.2664312720298767, 0.2459365576505661, 0.4918731153011322, 0.5410966277122498, 0.2705483138561249, 0.2705483138561249, 0.21631698310375214, 0.39622417092323303, 0.38765716552734375, 0.16941526532173157, 0.5082458257675171, 0.33883053064346313, 0.5120290517807007, 0.2194410264492035, 0.2925880551338196, 0.28530189394950867, 0.3146137297153473, 0.400595098733902, 0.3150627017021179, 0.3989197015762329, 0.28511378169059753, 0.368987113237381, 0.3317611515522003, 0.2994440793991089, 0.2769692838191986, 0.3225877285003662, 0.40079084038734436, 0.3716396689414978, 0.3929370641708374, 0.2353362888097763, 0.4282130002975464, 0.29100778698921204, 0.28104934096336365, 0.2594797611236572, 0.46129733324050903, 0.28110307455062866, 0.2776760756969452, 0.4627934694290161, 0.18511739373207092, 0.3229021728038788, 0.2852983772754669, 0.39156997203826904, 0.26375073194503784, 0.2549590468406677, 0.4835430085659027, 0.15130743384361267, 0.30261486768722534, 0.453922301530838, 0.2790919840335846, 0.21468614041805267, 0.49377813935279846, 0.4793396294116974, 0.2396698147058487, 0.27751240134239197, 0.23346096277236938, 0.4584324359893799, 0.30986636877059937, 0.2109069675207138, 0.47454068064689636, 0.3163604438304901, 0.21368664503097534, 0.3052666485309601, 0.4884266257286072, 0.2168680727481842, 0.41278865933418274, 0.3708936870098114, 0.47738417983055115, 0.28153425455093384, 0.24073219299316406, 0.29332083463668823, 0.43120667338371277, 0.27577170729637146, 0.2622286081314087, 0.4412100315093994, 0.2965680658817291, 0.2879284918308258, 0.21594637632369995, 0.5038748979568481, 0.5097310543060303, 0.25486552715301514, 0.25486552715301514, 0.25991103053092957, 0.25991103053092957, 0.490943044424057, 0.45763278007507324, 0.2735848128795624, 0.26861053705215454, 0.35782352089881897, 0.26994937658309937, 0.3725863993167877, 0.246197909116745, 0.47481024265289307, 0.26378345489501953, 0.33723747730255127, 0.22610239684581757, 0.4407080411911011, 0.2534491717815399, 0.2534491717815399, 0.5068983435630798, 0.23173463344573975, 0.4771007299423218, 0.2726289927959442, 0.29677778482437134, 0.4032306969165802, 0.30000361800193787, 0.24750137329101562, 0.3225501775741577, 0.4295346438884735], \"Term\": [\"\\\"manager\\\"\", \"\\\"manager\\\"\", \"\\\"manager\\\"\", \"'em\", \"'em\", \"'em\", \"(2)\", \"(2)\", \"(2)\", \"(in\", \"(in\", \"(in\", \"1,\", \"1,\", \"1,\", \"200\", \"200\", \"200\", \"2016.\", \"2016.\", \"2016.\", \"actual\", \"actual\", \"actual\", \"adult\", \"adult\", \"adult\", \"ago.\", \"ago.\", \"ago.\", \"alien\", \"alien\", \"alien\", \"annoying\", \"annoying\", \"annoying\", \"appetizers\", \"appetizers\", \"appetizers\", \"appointment\", \"appointment\", \"appointment\", \"ask\", \"ask\", \"ask\", \"asked\", \"asked\", \"asked\", \"attended\", \"attended\", \"attended\", \"bank,\", \"bank,\", \"bank,\", \"bar,\", \"bar,\", \"bar,\", \"bc\", \"bc\", \"bc\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"big\", \"big\", \"big\", \"bisque,\", \"bisque,\", \"bisque,\", \"bit\", \"bit\", \"bit\", \"boxed\", \"boxed\", \"boxed\", \"business.\", \"business.\", \"business.\", \"can't\", \"can't\", \"can't\", \"cant\", \"cant\", \"cant\", \"cheese\", \"cheese\", \"cheese\", \"chicken\", \"chicken\", \"chicken\", \"chipotle\", \"chipotle\", \"chipotle\", \"chips\", \"chips\", \"chips\", \"city.\", \"city.\", \"city.\", \"clean\", \"clean\", \"clean\", \"climb\", \"climb\", \"climb\", \"code\", \"code\", \"code\", \"come\", \"come\", \"come\", \"compensate\", \"compensate\", \"compensate\", \"convenience\", \"convenience\", \"convenience\", \"convenient\", \"convenient\", \"convenient\", \"cooked\", \"cooked\", \"cooked\", \"custard\", \"custard\", \"custard\", \"customer\", \"customer\", \"customer\", \"customers,\", \"customers,\", \"customers,\", \"del\", \"del\", \"del\", \"delicious\", \"delicious\", \"delicious\", \"didn't\", \"didn't\", \"didn't\", \"diego\", \"diego\", \"diego\", \"dinner\", \"dinner\", \"dinner\", \"dish.\", \"dish.\", \"dish.\", \"do,\", \"do,\", \"do,\", \"dogs\", \"dogs\", \"dogs\", \"don't\", \"don't\", \"don't\", \"done.\", \"done.\", \"done.\", \"door\", \"door\", \"door\", \"early\", \"early\", \"early\", \"easy\", \"easy\", \"easy\", \"eat\", \"eat\", \"eat\", \"eggs\", \"eggs\", \"eggs\", \"everyday,\", \"everyday,\", \"everyday,\", \"everyone,\", \"everyone,\", \"everyone,\", \"extended\", \"extended\", \"extended\", \"fast\", \"fast\", \"fast\", \"feel\", \"feel\", \"feel\", \"felt\", \"felt\", \"felt\", \"find\", \"find\", \"find\", \"fine\", \"fine\", \"fine\", \"flavor\", \"flavor\", \"flavor\", \"food\", \"food\", \"food\", \"food.\", \"food.\", \"food.\", \"fooled\", \"fooled\", \"fooled\", \"french\", \"french\", \"french\", \"friendly\", \"friendly\", \"friendly\", \"fruit\", \"fruit\", \"fruit\", \"fruits.\", \"fruits.\", \"fruits.\", \"fun\", \"fun\", \"fun\", \"gave\", \"gave\", \"gave\", \"good\", \"good\", \"good\", \"good.\", \"good.\", \"good.\", \"great\", \"great\", \"great\", \"great,\", \"great,\", \"great,\", \"guess\", \"guess\", \"guess\", \"happy\", \"happy\", \"happy\", \"hell\", \"hell\", \"hell\", \"highly\", \"highly\", \"highly\", \"husband\", \"husband\", \"husband\", \"i'll\", \"i'll\", \"i'll\", \"i'm\", \"i'm\", \"i'm\", \"i've\", \"i've\", \"i've\", \"in\\\"\", \"in\\\"\", \"in\\\"\", \"installer\", \"installer\", \"installer\", \"instructors\", \"instructors\", \"instructors\", \"it's\", \"it's\", \"it's\", \"it).\", \"it).\", \"it).\", \"it.\", \"it.\", \"it.\", \"job\", \"job\", \"job\", \"josh\", \"josh\", \"josh\", \"kitchen\", \"kitchen\", \"kitchen\", \"kitchen,\", \"kitchen,\", \"kitchen,\", \"know\", \"know\", \"know\", \"knowledgeable,\", \"knowledgeable,\", \"knowledgeable,\", \"latin\", \"latin\", \"latin\", \"legs\", \"legs\", \"legs\", \"like\", \"like\", \"like\", \"little\", \"little\", \"little\", \"looking\", \"looking\", \"looking\", \"lot\", \"lot\", \"lot\", \"loud,\", \"loud,\", \"loud,\", \"love\", \"love\", \"love\", \"loves\", \"loves\", \"loves\", \"makes\", \"makes\", \"makes\", \"mall\", \"mall\", \"mall\", \"mary\", \"mary\", \"mary\", \"mattress\", \"mattress\", \"mattress\", \"menu\", \"menu\", \"menu\", \"mexican\", \"mexican\", \"mexican\", \"minutes\", \"minutes\", \"minutes\", \"moved\", \"moved\", \"moved\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nick\", \"nick\", \"nick\", \"nicole\", \"nicole\", \"nicole\", \"night\", \"night\", \"night\", \"often,\", \"often,\", \"often,\", \"onions,\", \"onions,\", \"onions,\", \"order\", \"order\", \"order\", \"order,\", \"order,\", \"order,\", \"ordered\", \"ordered\", \"ordered\", \"owner\", \"owner\", \"owner\", \"pairing\", \"pairing\", \"pairing\", \"palate\", \"palate\", \"palate\", \"pancake\", \"pancake\", \"pancake\", \"patio\", \"patio\", \"patio\", \"people\", \"people\", \"people\", \"place\", \"place\", \"place\", \"point\", \"point\", \"point\", \"portion\", \"portion\", \"portion\", \"pretty\", \"pretty\", \"pretty\", \"price\", \"price\", \"price\", \"probably\", \"probably\", \"probably\", \"rare,\", \"rare,\", \"rare,\", \"read\", \"read\", \"read\", \"ready\", \"ready\", \"ready\", \"recommend\", \"recommend\", \"recommend\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant.\", \"restaurant.\", \"restaurant.\", \"right!\", \"right!\", \"right!\", \"rise\", \"rise\", \"rise\", \"rolls\", \"rolls\", \"rolls\", \"saves\", \"saves\", \"saves\", \"scallops\", \"scallops\", \"scallops\", \"scorpion\", \"scorpion\", \"scorpion\", \"service\", \"service\", \"service\", \"service,\", \"service,\", \"service,\", \"she's\", \"she's\", \"she's\", \"simple\", \"simple\", \"simple\", \"smoothies.\", \"smoothies.\", \"smoothies.\", \"souvlaki\", \"souvlaki\", \"souvlaki\", \"st\", \"st\", \"st\", \"staff\", \"staff\", \"staff\", \"stop\", \"stop\", \"stop\", \"stopping\", \"stopping\", \"stopping\", \"strings\", \"strings\", \"strings\", \"style.\", \"style.\", \"style.\", \"stylist\", \"stylist\", \"stylist\", \"swedish\", \"swedish\", \"swedish\", \"sweet\", \"sweet\", \"sweet\", \"tart.\", \"tart.\", \"tart.\", \"themed\", \"themed\", \"themed\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"time\", \"time\", \"time\", \"times\", \"times\", \"times\", \"told\", \"told\", \"told\", \"took\", \"took\", \"took\", \"town.\", \"town.\", \"town.\", \"tremendous\", \"tremendous\", \"tremendous\", \"try\", \"try\", \"try\", \"try.\", \"try.\", \"try.\", \"umbrella\", \"umbrella\", \"umbrella\", \"unfortunately,\", \"unfortunately,\", \"unfortunately,\", \"us,\", \"us,\", \"us,\", \"us.\", \"us.\", \"us.\", \"valentine's\", \"valentine's\", \"valentine's\", \"vehicle\", \"vehicle\", \"vehicle\", \"wait\", \"wait\", \"wait\", \"waiter\", \"waiter\", \"waiter\", \"waiting\", \"waiting\", \"waiting\", \"want\", \"want\", \"want\", \"warmly\", \"warmly\", \"warmly\", \"warn\", \"warn\", \"warn\", \"warned\", \"warned\", \"warned\", \"well,\", \"well,\", \"well,\", \"went\", \"went\", \"went\", \"wines\", \"wines\", \"wines\", \"working\", \"working\", \"working\", \"world,\", \"world,\", \"world,\", \"worse\", \"worse\", \"worse\", \"worth\", \"worth\", \"worth\", \"you're\", \"you're\", \"you're\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1592826441412645841373306683\", ldavis_el1592826441412645841373306683_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1592826441412645841373306683\", ldavis_el1592826441412645841373306683_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1592826441412645841373306683\", ldavis_el1592826441412645841373306683_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "1      0.003141  0.003510       1        1  33.416721\n",
              "2     -0.004998  0.000657       2        1  33.332592\n",
              "0      0.001857 -0.004167       3        1  33.250687, topic_info=       Term         Freq        Total Category  logprob  loglift\n",
              "15     like  3237.000000  3237.000000  Default  30.0000  30.0000\n",
              "174    good  3039.000000  3039.000000  Default  29.0000  29.0000\n",
              "584     i'm  1524.000000  1524.000000  Default  28.0000  28.0000\n",
              "201   great  3359.000000  3359.000000  Default  27.0000  27.0000\n",
              "740    feel   632.000000   632.000000  Default  26.0000  26.0000\n",
              "..      ...          ...          ...      ...      ...      ...\n",
              "745    love   425.370209  1550.312134   Topic3  -5.8612  -0.1922\n",
              "675  didn't   402.886566  1480.700806   Topic3  -5.9155  -0.2005\n",
              "121  people   358.548279  1161.143799   Topic3  -6.0321  -0.0740\n",
              "43    staff   353.460571  1232.492798   Topic3  -6.0464  -0.1479\n",
              "373   order   329.277740  1160.764160   Topic3  -6.1173  -0.1588\n",
              "\n",
              "[282 rows x 6 columns], token_table=      Topic      Freq       Term\n",
              "term                            \n",
              "2125      1  0.414089  \"manager\"\n",
              "2125      2  0.276060  \"manager\"\n",
              "2125      3  0.276060  \"manager\"\n",
              "2414      1  0.210777        'em\n",
              "2414      2  0.210777        'em\n",
              "...     ...       ...        ...\n",
              "769       2  0.403231      worth\n",
              "769       3  0.300004      worth\n",
              "949       1  0.247501     you're\n",
              "949       2  0.322550     you're\n",
              "949       3  0.429535     you're\n",
              "\n",
              "[603 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2pi0v_VGUmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFl0viKkGUmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwzSSygEGUmz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##                                                         Analysis\n",
        "\n",
        "     Topic Model, LDA(Latent Dirichlet Allcocation) is  used for uncovering hidden structure, e,g topics of reviews in a collection of texts of the restaurant yelp information. It made the analysis run faster because it reduced the dimensionality of space , it also collected the  documents that best represents the Unsupervised Learning, it gave  the number of clusters of topics, e,g.bgood or bad reviews on a restaurant, the service, and the food.  So by LDA topic modeling, we build clusters of topics.   We can tag the abstract “topics”  that best represents the customers opinions. It got user ratings of each of those subcategories and then train a model specifically to predict food rating for a review. Also by visualizations,  we  really easily can see how individual review contribute the whole review on different parts,such food, place, service.From this analysis, the manager  can  know some useful information what place they do good, what place they need improve such on food, sevice, and so on. It reflected the information to users and the owner. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB97cpvkGUm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhIc5PMYGUm6",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals\n",
        "\n",
        "Complete one of more of these to push your score towards a three: \n",
        "* Incorporate named entity recognition into your analysis\n",
        "* Compare vectorization methods in the classification section\n",
        "* Analyze more (or all) of the yelp dataset - this one is v. hard. \n",
        "* Use a generator object on the reviews file - this would help you with the analyzing the whole dataset.\n",
        "* Incorporate any of the other yelp dataset entities in your analysis (business, users, etc.)"
      ]
    }
  ]
}